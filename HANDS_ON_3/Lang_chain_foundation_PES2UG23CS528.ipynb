{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet python-dotenv langchain langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT496TNi79hF",
        "outputId": "fbf459a7-9043-4d90-b12d-439c771391bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9GaGAAvwSpo",
        "outputId": "7252f302-cba1-40a0-a190-a6c1abc9c319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain-google-genai\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "# Model A: The \"Accountant\" (Precision)\n",
        "llm_focused = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# Model B: The \"Poet\" (Creativity)\n",
        "llm_creative = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQDu3eYlxSgQ",
        "outputId": "d03dfc00-faaf-4588-ece8-82b7014eaffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (4.2.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.62.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6f41b8",
        "outputId": "e18d8b85-d1eb-40f8-a70c-054ab5a749f9"
      },
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "\n",
        "print(\"... FOCUSED (Temp = 0) ...\")\n",
        "print(f\" Run 1: (llm_focused.invoke(prompt).content)\")\n",
        "print(f\" Run 2: (llm_focused.invoke(prompt).content)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... FOCUSED (Temp = 0) ...\n",
            " Run 1: (llm_focused.invoke(prompt).content)\n",
            " Run 2: (llm_focused.invoke(prompt).content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- CREATIVE (Temp=1) ---\")\n",
        "print(f\"Run 1: (llm_creative.invoke(prompt).content)\")\n",
        "print(f\"Run 2: (llm_creative.invoke(prompt).content)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puw7CdkP2DB0",
        "outputId": "511d0bcf-57c5-4ff7-e39f-28ab9b35ea30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CREATIVE (Temp=1) ---\n",
            "Run 1: (llm_creative.invoke(prompt).content)\n",
            "Run 2: (llm_creative.invoke(prompt).content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n"
      ],
      "metadata": {
        "id": "M3lf6UeP2D_E"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a rude teenager. Use slang and don't care about grammar.\"),\n",
        "    HumanMessage(content=\"What is the capital of France?\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxZ_Epxb8jQH",
        "outputId": "56b62470-c99e-425f-90d3-350633770fdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ugh, like, it's Paris. Duh. What kinda question is that?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a translator. Translate {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "print(\"Required variables:\", template.input_variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9xa4L4D82AE",
        "outputId": "37cb4f67-621a-47a9-e6d1-039c7bbd7f26"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required variables: ['input_language', 'output_language', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = template.invoke({\n",
        "    \"input_language\": \"English\",\n",
        "    \"output_language\": \"Spanish\",\n",
        "    \"text\": \"Hello, how are you?\"\n",
        "})\n",
        "\n",
        "response = llm.invoke(prompt_value)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G-koB7k85vJ",
        "outputId": "dbd73f37-f6b9-451b-8ef7-145fc1acdfe6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, ¿cómo estás?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "raw_msg = llm.invoke(\"Say hello\")\n",
        "\n",
        "print(\"Raw Type:\", type(raw_msg))\n",
        "\n",
        "clean_text = parser.invoke(raw_msg)\n",
        "\n",
        "print(\"Parsed Type:\", type(clean_text))\n",
        "print(\"Content:\", clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARKU_N8688ag",
        "outputId": "0152abf0-64f7-407a-ede4-be8e3cd2f455"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Parsed Type: <class 'str'>\n",
            "Content: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "template = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a fun fact about {topic}.\"\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n"
      ],
      "metadata": {
        "id": "T_6TXBNm8_kE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = template.invoke({\"topic\": \"Crows\"})\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "final_text = parser.invoke(response_obj)\n",
        "\n",
        "print(final_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdFgYDI89DQx",
        "outputId": "bffad4ba-bc71-4a3f-fd02-5cfe28f645b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about crows:\n",
            "\n",
            "Crows are incredibly intelligent and have excellent memories, especially when it comes to humans! They can recognize individual human faces and remember if you've been kind or mean to them for years, even passing this information on to other crows. So, if you're nice to a crow, you might just make a friend (or an entire family of friends!) for life!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = template | llm | parser\n",
        "\n",
        "print(chain.invoke({\"topic\": \"Octopuses\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUfEmN579H7-",
        "outputId": "32b570e5-0076-4043-899d-f06dfdfaf6e0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun one:\n",
            "\n",
            "Octopuses have **three hearts**! Two pump blood through the gills, and the third circulates blood to the rest of the body. They also have **blue blood** due to a copper-rich protein called hemocyanin, which is more efficient at transporting oxygen in cold, low-oxygen environments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ASSIGNMENT\n",
        "from datetime import datetime\n",
        "\n",
        "current_year = datetime.now().year\n",
        "\n",
        "assignment_template = ChatPromptTemplate.from_template(\n",
        "    f\"\"\"\n",
        "    The current year is {current_year}.\n",
        "    For the movie {{movie}}, tell me:\n",
        "    1. Its release year.\n",
        "    2. How many years ago it was released from the current year.\n",
        "    Give answer in 2 lines only.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "assignment_chain = assignment_template | llm | StrOutputParser()\n",
        "\n",
        "print(assignment_chain.invoke({\"movie\": \"Inception\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN9w9zDp93vU",
        "outputId": "bd8df73a-6e82-4f65-8569-d1dc4b237685"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2010\n",
            "16 years ago\n"
          ]
        }
      ]
    }
  ]
}