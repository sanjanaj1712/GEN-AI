{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-huggingface sentence-transformers langchain-community faiss-cpu langchain-google-genai"
      ],
      "metadata": {
        "id": "XowE2gd8gZlt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from langchain_huggingface import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "I7IXLHrTgk5K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "print(\"Embedding model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEOnMReYgl9o",
        "outputId": "66d21b65-d099-4ff5-9c7a-ccf2745eb6f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Apple\")\n",
        "\n",
        "print(f\"Dimensionality: {len(vector)}\")\n",
        "print(f\"First 5 numbers: {vector[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qDuKthEgsrD",
        "outputId": "1f2e214b-b4c6-4d6a-8bc8-81fb0cba0d03"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality: 384\n",
            "First 5 numbers: [-0.006138487718999386, 0.03101177327334881, 0.06479360908269882, 0.01094149798154831, 0.005267191678285599]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "vec_cat = embeddings.embed_query(\"Cat\")\n",
        "vec_dog = embeddings.embed_query(\"Dog\")\n",
        "vec_car = embeddings.embed_query(\"Car\")\n",
        "\n",
        "print(f\"Cat vs Dog: {cosine_similarity(vec_cat, vec_dog):.4f}\")\n",
        "print(f\"Cat vs Car: {cosine_similarity(vec_cat, vec_car):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xVnVMWhgw3B",
        "outputId": "238367df-2e7d-48f9-9fb8-71a2349436e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat vs Dog: 0.6606\n",
            "Cat vs Car: 0.4633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDylvNatgzp7",
        "outputId": "10d071e3-ab68-4008-a91a-4b1283e78866"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Piyush's favorite food is Pizza with extra cheese.\"),\n",
        "    Document(page_content=\"The secret password to the lab is 'Blueberry'.\"),\n",
        "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "iocegNr1g_Fr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "eUU-dwaOinV0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"\n",
        "Answer based ONLY on the context below:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "result = chain.invoke(\"What is the secret password?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_F8SW7firEF",
        "outputId": "0d0f2246-27ea-4162-b5ab-2386a0bfdd47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The secret password to the lab is 'Blueberry'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Mock Data: 10,000 vectors of size 128\n",
        "d = 128\n",
        "nb = 10000\n",
        "xb = np.random.random((nb, d)).astype('float32')"
      ],
      "metadata": {
        "id": "7QyQs1fziwSu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(xb)\n",
        "print(f\"Flat Index contains {index.ntotal} vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm2LotmSiz8T",
        "outputId": "e4967c4d-4c44-4668-c9e8-84a6f560764f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat Index contains 10000 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlist = 100 # How many 'zip codes' (clusters) we want\n",
        "quantizer = faiss.IndexFlatL2(d) # The calculator for distance\n",
        "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "\n",
        "# We MUST train it first so it learns where the clusters are\n",
        "index_ivf.train(xb)\n",
        "index_ivf.add(xb)"
      ],
      "metadata": {
        "id": "ZLNClP9Ji2kj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = 16 # Number of connections per node (The 'Hub' factor)\n",
        "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
        "index_hnsw.add(xb)"
      ],
      "metadata": {
        "id": "hCRCBV0Ji6QN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 8 # Split vector into 8 sub-vectors\n",
        "index_pq = faiss.IndexPQ(d, m, 8)\n",
        "index_pq.train(xb)\n",
        "index_pq.add(xb)\n",
        "print(\"PQ Compression complete. RAM usage minimized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY0xyo_pi8xb",
        "outputId": "5086425b-713a-4606-8b83-3f5ca09a344a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PQ Compression complete. RAM usage minimized.\n"
          ]
        }
      ]
    }
  ]
}