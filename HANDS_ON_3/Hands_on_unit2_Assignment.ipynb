{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vIl19KI7khtR"
      },
      "outputs": [],
      "source": [
        "!pip install -q groq python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLTlDkcukjQK",
        "outputId": "a41cf383-0db2-48ea-dd8b-b538201a3562"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "MODEL_NAME = \"llama-3.1-8b-instant\""
      ],
      "metadata": {
        "id": "RROqGecXlRv9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a Senior Software Engineer.\n",
        "Be precise, technical, and code-focused.\n",
        "Provide debugging steps and corrected code when needed.\n",
        "Avoid unnecessary fluff.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a Customer Billing Support Specialist.\n",
        "Be empathetic, polite, and policy-driven.\n",
        "Explain refund policies clearly.\n",
        "Maintain a professional tone.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a friendly AI assistant.\n",
        "Handle casual conversation and general queries.\n",
        "Be helpful and concise.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"tool\": {\n",
        "        \"system_prompt\": \"TOOL_HANDLER\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "l3pvAatwlUSL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(user_input):\n",
        "    routing_prompt = f\"\"\"\n",
        "Classify this text into one of these categories:\n",
        "[technical, billing, general, tool]\n",
        "\n",
        "Return ONLY the category name.\n",
        "\n",
        "Text:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict intent classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": routing_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "    return category"
      ],
      "metadata": {
        "id": "_nXMg02JlVUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bitcoin_price():\n",
        "    # Mock data (you can replace with real API later)\n",
        "    return \"The current price of Bitcoin is approximately $63,450.\""
      ],
      "metadata": {
        "id": "7jDhAVc3leKL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_request(user_input):\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    print(f\"[Router Decision]: {category}\")\n",
        "\n",
        "    # Tool handling\n",
        "    if \"bitcoin\" in user_input.lower() or category == \"tool\":\n",
        "        return get_bitcoin_price()\n",
        "\n",
        "    # Fallback safety\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "9x3fYdiwle3w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say hello\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kHPZtMqlj1-",
        "outputId": "937d067b-b918-43ae-c23a-d8a77c1c1c20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_request(\"My python script is throwing an IndexError on line 5.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlxSknMqnJLn",
        "outputId": "7b0b95de-4e15-4348-d814-724b463e5b35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Decision]: technical\n",
            "I'm not seeing any code. Please provide the relevant code snippet where the IndexError is occurring. This will help me identify the issue and provide a solution.\n",
            "\n",
            "If you're not sure which line is causing the issue, you can also provide the full stacktrace. This will give me more information about the error.\n",
            "\n",
            "Once I have the code and/or stacktrace, I can guide you through debugging steps and provide a corrected version if needed.\n",
            "\n",
            "Example of what I'd like to see:\n",
            "\n",
            "* Code snippet where the error occurs\n",
            "* Full stacktrace (if available)\n",
            "\n",
            "```python\n",
            "# code snippet here\n",
            "```\n",
            "\n",
            "Let's get started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_request(\"I was charged twice for my subscription this month.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooiE11svoA_u",
        "outputId": "5936928e-68bc-4547-efa6-60d73ff6f1ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Decision]: billing\n",
            "I'm happy to help you with this issue. I can see that you've been charged twice for your subscription this month. I want to assure you that we're here to help and make things right.\n",
            "\n",
            "To process a refund for the duplicate charge, I'll need to verify some information with you. Can you please confirm your account details, including your name, email address, and the subscription plan you're on? This will help me locate your account and assist you more efficiently.\n",
            "\n",
            "Additionally, our refund policy states that we will refund any duplicate or unauthorized charges within 30 days of the original transaction date. Since you've contacted us within a reasonable timeframe, you're eligible for a refund.\n",
            "\n",
            "Once I've processed the refund, you should see the credit back in your account within 3-5 business days, depending on your bank's processing time.\n",
            "\n",
            "Is there anything else I can help you with or do you have any questions about our refund process?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_request(\"What is the current price of Bitcoin?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BkUXGZUoGv8",
        "outputId": "a6905b85-adc8-4184-f18a-5cad79dd8ec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Decision]: general\n",
            "The current price of Bitcoin is approximately $63,450.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This system uses an LLM-based intent router to classify user queries into predefined expert categories. Based on the classification, the system dynamically selects an expert-specific system prompt and generates a response using the Groq-hosted LLaMA model."
      ],
      "metadata": {
        "id": "JU6g8CQWoY7e"
      }
    }
  ]
}