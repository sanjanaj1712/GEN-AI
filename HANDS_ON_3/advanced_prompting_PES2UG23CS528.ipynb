{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfT7WAEe_Z3i",
        "outputId": "6a8c0452-0062-44b2-d7d0-ea308f9bdd38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet python-dotenv langchain langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiBF7QI1_j8x",
        "outputId": "8cb18472-30ae-410d-dc1b-eed8cb4e0474"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "lNoU6OMc_lpj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
        "\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "\n",
        "print(\"--- STANDARD ---\")\n",
        "print(llm.invoke(prompt_standard).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jS-HZwd_nQ8",
        "outputId": "526abc51-9124-437c-9459-6b282b6082be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD ---\n",
            "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
            "\n",
            "2 cans * 3 tennis balls per can = 6 tennis balls\n",
            "\n",
            "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
            "\n",
            "5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- CHAIN OF THOUGHT ---\")\n",
        "print(llm.invoke(prompt_cot).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfji4dtZ_p34",
        "outputId": "0f04aab2-90c3-42d6-ac77-aa8b7641c367"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CHAIN OF THOUGHT ---\n",
            "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
            "\n",
            "1. Roger already has 5 tennis balls.\n",
            "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
            "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "6jqwjVh7_roF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
        "\n",
        "# Step 1: Branch Generator\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give one unique creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# Step 2: Judge\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three solutions for: '{problem}'\n",
        "\n",
        "    1: {sol1}\n",
        "    2: {sol2}\n",
        "    3: {sol3}\n",
        "\n",
        "    Act as a Child Psychologist.\n",
        "    Pick the most sustainable solution (not bribery).\n",
        "    Explain why.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- TREE OF THOUGHTS ---\")\n",
        "print(tot_chain.invoke(problem))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObB-JaXR_tMo",
        "outputId": "a419e60d-43da-44db-e7a0-273b37441355"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TREE OF THOUGHTS ---\n",
            "As a child psychologist, I would recommend **Solution 1: \"Veggie Faces\"** and **Solution 3: Create a \"Veggie Face\" on Their Plate** as the most sustainable solutions, but with some slight modifications to ensure they align with healthy eating habits.\n",
            "\n",
            "**Why \"Veggie Faces\" and \"Veggie Face\" are the most sustainable solutions:**\n",
            "\n",
            "1. **Engagement:** Both solutions encourage engagement and creativity, which are essential for children to develop a positive relationship with food.\n",
            "2. **Positive associations:** By making mealtime more fun and interactive, children are more likely to develop positive associations with vegetables and other healthy foods.\n",
            "3. **Gradual exposure:** Both solutions allow for gradual exposure to new vegetables, which is essential for introducing children to new foods.\n",
            "4. **No bribery:** Unlike some other solutions that involve offering rewards or treats for eating vegetables, \"Veggie Faces\" and \"Veggie Face\" are not bribing children to eat certain foods.\n",
            "5. **Development of culinary skills:** Both solutions encourage children to participate in meal preparation and develop their culinary skills, which are essential for healthy eating habits.\n",
            "6. **Promotes self-regulation:** By allowing children to create their own \"Veggie Faces,\" they develop self-regulation skills, which are essential for making healthy food choices.\n",
            "\n",
            "**Modifications to ensure sustainability:**\n",
            "\n",
            "1. **Involve your child in the process:** Encourage your child to participate in creating the \"Veggie Face\" or \"Veggie Faces\" by choosing the vegetables, arranging them, and deciding on the design.\n",
            "2. **Use a variety of vegetables:** Encourage your child to try different vegetables and experiment with new combinations.\n",
            "3. **Make it a routine:** Incorporate \"Veggie Faces\" and \"Veggie Face\" into your child's regular meal routine, so they become accustomed to seeing and eating a variety of vegetables.\n",
            "4. **Gradually increase the variety:** As your child becomes more comfortable with eating vegetables, gradually introduce new and unfamiliar vegetables to their diet.\n",
            "5. **Encourage self-regulation:** Allow your child to make choices about what vegetables to eat and how to arrange them, promoting self-regulation and autonomy.\n",
            "\n",
            "By implementing these modifications, \"Veggie Faces\" and \"Veggie Face\" can become sustainable solutions that promote healthy eating habits and a positive relationship with vegetables in children.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "zswJzmaA_u4p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three movie ideas for '{topic}':\n",
        "\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romance: {draft_romance}\n",
        "    3. Horror: {draft_horror}\n",
        "\n",
        "    Combine the TECHNOLOGY of Sci-Fi,\n",
        "    the PASSION of Romance,\n",
        "    and the FEAR of Horror.\n",
        "\n",
        "    Write one paragraph.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- GRAPH OF THOUGHTS ---\")\n",
        "print(got_chain.invoke(\"Time Travel\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb25qDHJ_xqk",
        "outputId": "235a071c-07e2-44c3-d961-1889102cd7ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- GRAPH OF THOUGHTS ---\n",
            "As Emily, a brilliant and daring physicist, travels back to the 1920s in her time machine, she's immediately captivated by the charming soldier, James, who sweeps her off her feet with his dashing smile and romantic gestures. But as they fall deeply in love, Emily begins to notice strange occurrences that hint at a dark presence lurking in the shadows - a malevolent entity from the past that has been unleashed by her time travel, and is now stalking them relentlessly, determined to claim their souls. As Emily and James fight to survive the night and prevent a catastrophic future, they must also confront the devastating consequences of changing the past, and the ultimate question: can their love be strong enough to overcome the horrors that threaten to tear them apart, or will the very fabric of time tear them asunder?\n"
          ]
        }
      ]
    }
  ]
}